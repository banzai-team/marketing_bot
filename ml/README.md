# Сервис для анализа диалогов

## Стек

- Python 3.10
- Fastapi
- Torch
- Transformers

## Документация 

### swagger

- \<service host\>/docs

## Запуск сервиса

```make build up```

## Мониторинг

### Health-check

Endpoint - /health
Ответ 200

## Алгоритмы и модели

### Модель определения матов, недопустимых высказываний, политики

Мы использовали модель rutiny-bert, и датасет с токсичными коментариями, расширив его политическими высказываниями.

Ссылка на изначальный датасет: https://cups.online/ru/tasks/1048

Ссылка на дополнительный датасет: https://arxiv.org/abs/2103.05345

### Модель векторизации диалогов

Для векторизации диалогов мы протестировали такие подходы как: ``BM25``, ``Tf-idf``, но по полученным нами метрикам лучшая точность оказалась у ембедингов bert-based модели.

Мы исследовали разлиные модели bert-based обученные на русском языке, но остановились на: 
``rubert-tiny``, так как она не большая, что позволяет быстро векторизовать диалог.

Также нами были опробованы подходы с ллм-моделями: для сумаризации диалога, поиска стоп тем и определения релевантности делать предложение клиенту, но из-за отсутствия GPU и ограничени  на время работы сервиса нам пришлось отказаться от этих гипотез. Обращаем внимание, что при наличии GPU возможно интегрировать ллм молели под некоторые из задач.

Ссылка на изпользуемую модель веркторизации текста: https://huggingface.co/cointegrated/rubert-tiny2

### Модель классификации диалогов в векторной форме

Так как у нас был небольшой датасет, мы протестировали классические модели маинного обучения. Но остановились на логистической регресии, что аналогично классической класификационной голове в bert моделях.

При расширении датасета диалогов, конечно можно обучить полноценную класификационную версию bert модели, но на данный момент наш бейзлайн показал ``F1-метрику`` -  ``0.83``.
